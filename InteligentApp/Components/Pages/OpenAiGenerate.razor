@page "/openai-generate"

<!--
    OpenAiGenerate.razor
    Blazor component for generating text using GPT-4.
    - Loads prompts from CSV.
    - Allows user to select or enter a prompt.
    - Displays generated response.
-->

<h3>Generowanie tekstu od GPT-4</h3>

<p>Wpisz poniżej prompt (pytanie lub polecenie), a następnie kliknij przycisk, aby wygenerować odpowiedź od modelu GPT-4</p>

<div class="mb-3">
    <label class="mb-2">Wybierz prompt:</label>
    <select class="form-select" @onchange="OnPromptSelected">
        <option value="">-- Wybierz prompt --</option>
        @foreach (var prompt in _availablePrompts)
        {
            <option value="@prompt">@prompt</option>
        }
    </select>
</div>

<div class="mb-3">
    <label for="promptInput" class="form-label">Prompt:</label>
    <textarea id="promptInput" class="form-control" rows="3" @bind="_userPrompt"></textarea>
</div>

<button class="btn btn-primary" @onclick="GenerateTextAsync">Generuj tekst</button>

@if (_isLoading)
{
    <p class="mt-3">Proszę poczekać, generuję odpowiedź...</p>
}
else if (!string.IsNullOrWhiteSpace(_generatedText))
{
    <div>
        <h4>Wynik:</h4>
        <p>@_generatedText</p>
    </div>
}

@code {
    /// <summary>
    /// User's prompt input.
    /// </summary>
    private string _userPrompt = string.Empty;

    /// <summary>
    /// Generated text from GPT-4.
    /// </summary>
    private string _generatedText = string.Empty;

    /// <summary>
    /// Indicates if the response is being generated.
    /// </summary>
    private bool _isLoading = false;

    /// <summary>
    /// List of available prompts loaded from CSV.
    /// </summary>
    private readonly List<string> _availablePrompts = new();

    [Inject]
    public IHttpClientFactory HttpClientFactory { get; set; }

    [Inject]
    public IWebHostEnvironment Environment { get; set; }

    /// <summary>
    /// Loads prompts from CSV file on initialization.
    /// </summary>
    protected override void OnInitialized()
    {
        LoadPromptsFromCsv("prompts.csv");
    }

    /// <summary>
    /// Loads prompts from a CSV file located in wwwroot.
    /// </summary>
    /// <param name="csvFileName">CSV file name.</param>
    private void LoadPromptsFromCsv(string csvFileName)
    {
        var csvPath = Path.Combine(Environment.WebRootPath, csvFileName);
        if (!File.Exists(csvPath))
            return;

        foreach (var line in File.ReadLines(csvPath).Skip(1))
        {
            var prompt = line.Trim().Trim('"');
            if (!string.IsNullOrWhiteSpace(prompt))
                _availablePrompts.Add(prompt);
        }
    }

    /// <summary>
    /// Handles prompt selection from dropdown.
    /// </summary>
    private void OnPromptSelected(ChangeEventArgs args)
    {
        var selected = args.Value?.ToString();
        if (!string.IsNullOrWhiteSpace(selected))
            _userPrompt = selected;
    }

    /// <summary>
    /// Generates text using GPT-4 based on the user's prompt.
    /// </summary>
    private async Task GenerateTextAsync()
    {
        if (string.IsNullOrWhiteSpace(_userPrompt))
        {
            _generatedText = "Proszę wpisać prompt.";
            return;
        }

        _isLoading = true;
        _generatedText = string.Empty;

        _generatedText = await GetOpenAiResponseAsync(_userPrompt);
        _isLoading = false;
    }

    /// <summary>
    /// Sends a prompt to OpenAI and returns the response.
    /// </summary>
    /// <param name="userPrompt">Prompt to send.</param>
    /// <returns>Response text from OpenAI.</returns>
    private async Task<string> GetOpenAiResponseAsync(string userPrompt)
    {
        try
        {
            var client = HttpClientFactory.CreateClient("OpenAI");

            var requestBody = new
            {
                model = "gpt-4",
                messages = new[]
                {
                    new { role = "system", content = "Jesteś pomocnym asystentem." },
                    new { role = "user", content = userPrompt }
                },
                max_tokens = 500,
                temperature = 0.7
            };

            using var response = await client.PostAsJsonAsync("", requestBody);

            if (!response.IsSuccessStatusCode)
                return $"Error: {response.StatusCode}, Przepraszam ale nie udało mi się uzyskać odpowiedzi od AI";

            var jsonResponse = await response.Content.ReadFromJsonAsync<ChatCompletionResponse>();
            var answer = jsonResponse?.Choices?.FirstOrDefault()?.Message?.Content?.Trim();
            return answer ?? "Przepraszam ale nie udało mi się uzyskać odpowiedzi od AI";
        }
        catch (Exception ex)
        {
            return $"Wystąpił błąd: {ex.Message}";
        }
    }
}
